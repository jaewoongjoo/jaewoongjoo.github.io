---
title: "4.1. Models for Nominal data"
---

<style type="text/css">
 
  body, td {
    font-size: 15px;
  }
pre {
  font-size: 15px
}
</style>



##### Remark 

Suppose categorical response has $J>2$ categories. 

Sampling model: Independent miltinomial distribution with probabilities $\{ \pi_1(x), \ldots, \pi_J(x)\}$ at each setting $x$ of explanatory variables. 

Then we have two cases

1. Unordered categories(nominal scale),

2. Ordered categories(ordinal scale).

&nbsp;&nbsp;

##### Remark

For the unordered categories, Basiline category logit models are used. 

Choose baseline category (say, $J$) and form logits

$$\begin{eqnarray*}
\log\left\{\frac{\pi_j(x)}{\pi_J(x)} \right\}&=&\log\left\{\frac{\pi_j(x)/(\pi_j(x)+\pi_J(x))}{\pi_J(x)/(\pi_j(x)+\pi_J(x))} \right\}\\
&=&\text{logit}\left\{P(Y=j|Y=j \mbox{ or }Y=J) \right\}.
\end{eqnarray*}$$
Then, we can set up a model such that
$$
\log\left\{\frac{\pi_j(x)}{\pi_J(x)} \right\}=\alpha_j+\beta_j'x, \mbox{ }j=1,2,\ldots,J-1.
$$

&nbsp;&nbsp;

##### Remark
1. Other logits are determined by this basic set of $J-1$ logits: For $a<b<J$, 
$$
\log\left\{\frac{\pi_a(x)}{\pi_b(x)} \right\}=\log\left\{\frac{\pi_a(x)}{\pi_J(x)} \right\}-\log\left\{\frac{\pi_b(x)}{\pi_J(x)} \right\} = (\alpha_a-\alpha_b)+(\beta_a'-\beta_b')x.
$$

2. For subject $i$,
$$
\pi_j(x_i)=\frac{\exp(\eta_{ij})}{\sum_h\exp(\eta_{ih})}=\frac{\exp(\eta_{ij})}{1+\sum_{h=1}^{J-1}\exp(\eta_{ih})}
$$
with $\eta_{ij}=\alpha_j+\beta_j'x_i$ for which
$$
\log\left\{\frac{\pi_j(x_i)}{\pi_J(x_i)}\right\}= (\alpha_j-\alpha_J)+(\beta_j-\beta_J)'x_i.
$$
(WLOG, $\alpha_J=\beta_J=0$). 어차피 같은 값이 모든 $j=1,2,\ldots,J-1$에 빼지는 것이기 때문이다.

&nbsp;&nbsp;

  * Note : 
$$\begin{eqnarray*}
  \log\left\{\frac{\pi_j(x_i)}{\pi_J(x_i)}\right\}&=&\log\left\{\frac{\pi_j(x_i)}{1-(\pi_1+\cdots+\pi_{J-1}(x_i))}\right\} = \alpha_j+\beta_j'x_i\\
   \implies \exp(\eta_{ij})&=&1-\frac{\pi_j(x_i)}{1-(\pi_1(x_i)+\cdots+\pi_{J-1}(x_i))}\\
   \implies \exp(\eta_{iJ})&=&1-\frac{\pi_J(x_i)}{1-(\pi_1(x_i)+\cdots+\pi_{J-1}(x_i))}=1.
\end{eqnarray*}$$


&nbsp;&nbsp;

3. Let $y_{ij}=1$ if subject $i$ makes response in category $j$, $y_{ij}=0$ otherwise, i.e.,

   $y_i=(y_{i1},\ldots,y_{iJ})$ such that $\sum_{j=1}^Jy_{ij}=1.$
   
   Let $\mu_{ij}=E(Y_{ij})=\pi_j(x_i)$.

   More general "Multivariate GLM" has form
   $$
   g(\mu_{ij})=\alpha_j+x_i'\beta_j, \mbox{ }j=1,2,\ldots,J-1.
   $$

&nbsp;&nbsp;

4. For a particular observation, let   $y_i=(y_{i1},\ldots,y_{iJ})$. Then, contribution to log-likelihood for $i$ is 
$$\begin{eqnarray*}
  \log\left\{\prod_j\pi_j^{y_{ij}}(x_i)\right\} &=& \sum_{j=1}^{J-1}y_{ij}\log\pi_j(x_i)+\left(1-\sum_{j=1}^{J-1}y_j \right)\log\left\{1-\sum_{j=1}^{J-1}\pi_j(x_i)\right\} \\
  &=&\sum_{j=1}^{J-1}y_{ij}\log\frac{\pi_j(x_i)}{1-\sum_{j=1}^{J-1}\pi_j(x_i)}+\log\left\{1-\sum_{j=1}^{J-1}\pi_j(x_i)\right\}.
\end{eqnarray*}$$

So, baseline-category logit models are canonical in multivariate exponential family.

&nbsp;&nbsp;

##### Remark
Let $Y=Y_1,\ldots, Y_N)$ are independent observations. Then, the joint distribution is
$$\begin{eqnarray*}
  f(y_1,\ldots,y_n)=\text{...}
\end{eqnarray*}$$


&nbsp;&nbsp;


[back](../glm.html)

